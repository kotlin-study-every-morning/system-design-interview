## 1단계
### 개략적 규모 추정
- DAU = 10,000,000 명
- 하루 1인당 10번 검색
- 검색 시 평균 20Byte 입력
  - 인코딩 = ASCII, 1문자 = 1Byte
- 각 입력마다 백엔드 요청 -> 1회 검색 시 20회 요청
- 약 24,000QPS
- 질의 중 20%는 생성 -> 하루 0.4GB씩 추가

## 2단계
### 데이터 수집 서비스
- 각 문자열의 HIT 빈도를 데이터로 저장

### 질의 서비스
- 검색한 문자열을 통해 저장된 문자열과 매치 시켜 가장 높은 빈도를 가진 top5를 조회
- 데이터가 매우 많아지면 병목 가능성 상승

## 3단계
### 트라이 자료구조
- 트리의 발전형으로 문자열을 빠르게 조회 하기 위한 자료구조
- 각 노드에 문자열을 저장
- 단말 노드에는 문자열의 빈도를 저장
- 접두어 최대 길이 제한을 통해 시간 복잡도 해소
- 각 노드별 인기 검색어를 캐시해두어 시간 복잡도 해소

### 데이터 수집 서비스
- 2단계의 구조는 2가지 문제를 가지고 있다.
  1. 매일 수천만 데이터의 갱신은 부하 가중
  2. 트라이 구성 후 인기 검색어 변경 빈도 하락으로 비효율적 갱신
- 데이터 분석 서비스 로그 추가로 원본 데이터 미리 보관
- 로그 취합 서버 추가로 데이터 형식 일치 취합의 빈도는 결과의 실시간성을 고려하며 이 설계에서는 일주일로 가정
- 취합된 데이터를 작업 서버로 전달하여 트라이 구조 생성 및 갱신
- 트라이 캐시를 통해 데이터 조회 연산 속도 증대
- 트라이 데이터베이스를 통해 지속성 데이터 저장, 문서 저장소 / 키-값 저장소 중 선택

### 질의 서비스
- 2단계 구조를 개선한다.
- 로드 밸런서를 통한 부하 분산
- 트라이 캐시를 통한 요청 응답
- 트라이 데이터베이스를 통한 지속성 데이터 요청 및 캐시미스 대응

### 트라이 연산
- 트라이 생성
  - 작업 서버로 부터 생성 되며 취합된 데이터 분석 로그을 통해 생성한다.
- 트라이 갱신
  1. 매주 한번 갱신 하며 기존 트라이를 대체
  2. 각 노드별 개별 갱신
     - 성능이 좋지 않음
     - 트라이가 작을 경우 고려해볼 수 있음
- 검색어 삭제
  - 혐오성, 폭력적, 성적 질의를 제거한다.
  - 필터 계층을 통해 부적절 질의어를 필터링 하도록 한다.

### 저장소 규모 확장
- 영어를 기준으로만 본다면 알파벳 순으로 서버를 샤딩 한다.
- 서버가 늘어날 수록 각 알파벳 범위를 좁혀나간다.
- 최대 알파벳 갯수가 늘어난다면 두글자 스펠링 범위로 더욱 좁힌다.